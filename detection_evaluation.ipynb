{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "import os, sys\n",
    "import spikeextractors as se\n",
    "import ast\n",
    "from detection_helper_functions import getSortedDetectionInfo, getNClosestPositions\n",
    "from detection_helper_functions import runThresholdDetection, getDist, evaluateDetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up extractors and dataset\n",
    "dataset_directory = 'path-to-mea-rec-h5-file' # folder or hdf5 file\n",
    "dataset = h5py.File(dataset_directory)\n",
    "recording = se.MEArecRecordingExtractor(recording_path=dataset_directory)\n",
    "sorting = se.MEArecSortingExtractor(recording_path=dataset_directory)\n",
    "\n",
    "neuron_locs = []\n",
    "for i in range(50):\n",
    "    annotation_hf = dataset['spiketrains'][str(i)]['annotations']\n",
    "    annotation_dict = ast.literal_eval(annotation_hf[()])\n",
    "    neuron_locs.append(annotation_dict['loc'])\n",
    "\n",
    "#Probe channel positions and locations of the neurons in 2D numpy arrays\n",
    "channel_positions = np.asarray(dataset['positions'])\n",
    "neuron_locs = np.asarray(neuron_locs)\n",
    "\n",
    "#Return the spike times and associated neurons that fired in two numpy arrays\n",
    "firing_times, firing_neurons = getSortedDetectionInfo(sorting)\n",
    "\n",
    "print(\"Num Channels: \" + str(len(recording.getChannelIds())))\n",
    "print(\"Num Frames: \" + str(recording.getNumFrames()))\n",
    "print(\"Firing times: \" + str(firing_times))\n",
    "print(\"Firing neurons: \" + str(firing_neurons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get distance matrix between all channels (channels x channels dimension)\n",
    "dist_matrix = []\n",
    "for channel_position in channel_positions:\n",
    "    closest_channels, closest_dists = getNClosestPositions(channel_positions.shape[0], \n",
    "                                                           channel_position, \n",
    "                                                           channel_positions)\n",
    "    inds = np.argsort(closest_channels)\n",
    "    closest_channels = closest_channels[inds]\n",
    "    closest_dists = closest_dists[inds]\n",
    "    dist_matrix.append(closest_dists)\n",
    "dist_matrix = np.asarray(dist_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot traces from channel and spike times from closest neuron for the given frames\n",
    "channel_ids = [5]\n",
    "t0 = 0\n",
    "t1 = 10000\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(recording.getTraces(channel_ids=channel_ids, start_frame=t0, end_frame=t1)[0])\n",
    "closest_neurons, _ = getNClosestPositions(5, channel_positions[channel_ids[0]], neuron_locs)\n",
    "closest_neuron = closest_neurons[0]\n",
    "closest_neuron_st = sorting.getUnitSpikeTrain(unit_id=closest_neuron)\n",
    "print(closest_neuron)\n",
    "num_spikes = 0\n",
    "spike_times = []\n",
    "for spike_time in sorting.getUnitSpikeTrain(unit_id=closest_neuron, start_frame=t0, end_frame=t1):\n",
    "    plt.axvline(x=spike_time - t0, color='red', linestyle='--', alpha=.5)\n",
    "    num_spikes += 1\n",
    "    spike_times.append(spike_time)\n",
    "plt.axhline(-40, color='black', linestyle='dashdot')\n",
    "plt.xlabel('Frames')\n",
    "plt.xlabel('mV')\n",
    "print('Channel: ' + str(channel_ids[0]))\n",
    "print('Closest Neuron: ' + str(closest_neuron))\n",
    "print('Neuron ' + str(closest_neuron) + ' spiked ' + str(num_spikes) + ' times in frames ' +  str(t0) + '-' + str(t1) + ' at ' + str(spike_times))\n",
    "\n",
    "snippets = recording.getSnippets(reference_frames=spike_times, snippet_len=50, channel_ids=channel_ids)\n",
    "plt.figure()\n",
    "for snippet in snippets:\n",
    "    plt.plot(snippet[0])\n",
    "plt.xlabel('Frames')\n",
    "plt.xlabel('mV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic detection method for spikes for a channel in-between given frames (thresholding and peak detection)\n",
    "channel_ids = range(100)\n",
    "t0 = 0\n",
    "t1 = 1920000\n",
    "threshold = 40\n",
    "refractory_period = 10\n",
    "duplicate_radius = 100\n",
    "\n",
    "detected_firing_times, detected_channels = runThresholdDetection(channel_ids, \n",
    "                                                                 t0, \n",
    "                                                                 t1, \n",
    "                                                                 threshold, \n",
    "                                                                 refractory_period,\n",
    "                                                                 duplicate_radius,\n",
    "                                                                 dist_matrix,\n",
    "                                                                 recording\n",
    "                                                                )\n",
    "print(\"Num detected events: \" + str(detected_firing_times.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluating the detection results(detected_firing_times is sorted numpy array [0, 2, 100, 240, ...]) and\n",
    "# detected_channels is the corresponding channels the spikes have largest amplitudes on [34, 12, 23, 26, 99, ...]\n",
    "max_neuron_channel_dist = 100 #Dist (in microns) from channels to unit locations for them to be considered candidates for the spike\n",
    "matched_events, unmatched_detections, unmatched_firings = evaluateDetection(\n",
    "                                                                            detected_firing_times, \n",
    "                                                                            detected_channels, \n",
    "                                                                            firing_times, \n",
    "                                                                            firing_neurons, \n",
    "                                                                            channel_positions, \n",
    "                                                                            neuron_locs,\n",
    "                                                                            max_neuron_channel_dist, \n",
    "                                                                            jitter=10 #Frames allowed between detection and true event\n",
    "                                                                           )\n",
    "print(\"True Positives: \" + str(len(matched_events)))\n",
    "print(\"False Positives: \" + str(len(unmatched_detections)))\n",
    "print(\"False Negatives: \" + str(len(unmatched_firings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Understanding the evaluation results afterwards\n",
    "\n",
    "#(Detected frame, matched ground truth frame, detected channel) (True positive)\n",
    "print(\"First matched event: \" + str(matched_events[0]))\n",
    "\n",
    "#(Detected frame, detected channel) (False positive)\n",
    "print(\"First unmatched detection: \" + str(unmatched_detections[0]))\n",
    "\n",
    "#(Firing time, firing neuron) (False negative)\n",
    "print(\"First ground truth unmatched: \" + str((unmatched_firings[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot unmatched detections\n",
    "channel_ids = [67]\n",
    "t0 = 0\n",
    "t1 = 100000\n",
    "\n",
    "bad_detections = [detection for detection in unmatched_detections if detection[1] == channel_ids[0] and detection[0] <= t1 and detection[0] >= t0]\n",
    "print(\"Not matched detections: \"+ str(bad_detections))\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(recording.getTraces(channel_ids=channel_ids, start_frame=t0, end_frame=t1)[0])\n",
    "closest_neurons, _ = getNClosestPositions(5, channel_positions[channel_ids[0]], neuron_locs)\n",
    "for bad_detection in bad_detections:\n",
    "    plt.axvline(x=bad_detection[0] - t0, color='red', linestyle='--', alpha=.5)\n",
    "    \n",
    "plt.axhline(-40, color='black', linestyle='dashdot')\n",
    "print('Channel: ' + str(channel_ids[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:spikeinterface]",
   "language": "python",
   "name": "conda-env-spikeinterface-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
